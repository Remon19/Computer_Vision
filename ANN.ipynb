{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.datasets import load_iris\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## making custom dataset class for iris\n",
    "\n",
    "class IRISDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, data, labels, transform=None) -> None:\n",
    "        super(Dataset).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            sample = self.transform(self.data[index])\n",
    "        else:\n",
    "            sample = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return sample, label\n",
    "    \n",
    "    def train_test_split(self, split_ratio=0.7):\n",
    "        \n",
    "        shuffl_idx = list(range(len(self)))\n",
    "        random.shuffle(shuffl_idx)\n",
    "        split_idx = int(split_ratio*len(shuffl_idx))\n",
    "        train_dataset = IRISDataSet(self.data[:split_idx], \n",
    "                                    self.labels[:split_idx], self.transform)\n",
    "        test_dataset = IRISDataSet(self.data[split_idx:],\n",
    "                                   self.labels[split_idx:], self.transform)\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a Neural Network Class\n",
    "\n",
    "class NNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size:int, hidden_layers:list, num_classes) -> None:\n",
    "        super(NNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_layers[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_relu = nn.ModuleList()\n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            self.hidden_relu.append(nn.ReLU())\n",
    "\n",
    "        self.l_out = nn.Linear(hidden_layers[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu1(x)\n",
    "        for hidden, relu in zip(self.hidden_layers, self.hidden_relu):\n",
    "            x = hidden(x)\n",
    "            x = relu(x)\n",
    "\n",
    "        out = self.l_out(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data preperation\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "data = iris.data\n",
    "X = torch.from_numpy(data[:].values) \n",
    "y = torch.from_numpy(iris.target[:].values)\n",
    "# print(y, y.shape)\n",
    "# y = y.reshape((-1,1))\n",
    "\n",
    "dataset = IRISDataSet(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting into train and test\n",
    "train_dataset, test_dataset = dataset.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataloaders\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## device to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNet(\n",
      "  (l1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (hidden_relu): ModuleList(\n",
      "    (0): ReLU()\n",
      "  )\n",
      "  (l_out): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## instatiating an object of NNet\n",
    "\n",
    "model = NNet(4, [10, 10], 3).to(device)\n",
    "print(model)\n",
    "# x = torch.randn(8,4)\n",
    "# print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "creterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Training Accuracy: 0.95\t Val. Accuracy: 0.00.\n",
      "Epoch: 2\t Training Accuracy: 0.95\t Val. Accuracy: 0.00.\n",
      "Epoch: 3\t Training Accuracy: 0.95\t Val. Accuracy: 0.00.\n",
      "Epoch: 4\t Training Accuracy: 0.95\t Val. Accuracy: 0.00.\n",
      "Epoch: 5\t Training Accuracy: 0.95\t Val. Accuracy: 0.00.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        # Get data and targets to cuda if available\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #forward\n",
    "        scores = model(data)\n",
    "        # print(scores.shape)\n",
    "        # print(targets.shape)\n",
    "        loss = creterion(scores, targets)\n",
    "\n",
    "        # check accuracy\n",
    "        _,preds = scores.max(1)\n",
    "        # print(preds.shape)\n",
    "        # print(y.shape)\n",
    "        num_correct += (preds == targets).sum()\n",
    "        num_samples += preds.size(0)\n",
    "\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "    acc_train = num_correct/num_samples\n",
    "\n",
    "    # calculate accuracy on validation data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, targets in val_dataloader:\n",
    "\n",
    "            data = data.to(device, dtype=torch.float32)\n",
    "            targets = targets.to(device)\n",
    "            scores = model(data)\n",
    "            _,preds = scores.max(1)\n",
    "            num_correct += (preds == targets).sum()\n",
    "            num_samples += preds.size(0)\n",
    "    model.train()\n",
    "    acc_val = num_correct/ num_samples\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}\\t Training Accuracy: {acc_train:0.2f}\\t Val. Accuracy: {acc_val:0.2f}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
